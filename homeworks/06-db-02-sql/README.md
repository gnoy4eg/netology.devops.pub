# Домашнее задание к занятию "6.2. SQL"

## Введение

Перед выполнением задания вы можете ознакомиться с 
[дополнительными материалами](https://github.com/netology-code/virt-homeworks/tree/master/additional/README.md).

## Задача 1

Используя docker поднимите инстанс PostgreSQL (версию 12) c 2 volume, 
в который будут складываться данные БД и бэкапы.

Приведите получившуюся команду или docker-compose манифест.

Ответ:  
Чуть-чуть усложню себе задачу.  
Подойдем к решению задачи с подходом IaC (заодно потренируемся -_-). Поднимать инстанс буду на YandexCloud. Промежуточные результаты, не относящиеся к решению конкретной задачи в ДЗ, буду прятать под спойлер.
Необходимый инстанс будет подниматься автоматически.  

<details>
  <summary>Console</summary>

Создаем временную подсеть, билдим образ системы, удаляем временную подсеть, проверяем наличие робота, созданный image, генерируем key.json для Terraform'а
```bash
[gnoy@manjarokde-ws01 packer]$ yc vpc network create --name net --labels my-label=netology --description "my build network via yc" && yc vpc subnet create --name my-subnet-a --zone ru-central1-a --range 10.1.2.0/24 --network-name net --description "my build subnet via yc"
id: enplguu8t6nqraj8upp2
folder_id: b1g27gpcstr1l1bi3a22
created_at: "2022-02-15T10:55:00Z"
name: net
description: my build network via yc
labels:
  my-label: netology

id: e9b3hea97tekhsgsg754
folder_id: b1g27gpcstr1l1bi3a22
created_at: "2022-02-15T10:55:02Z"
name: my-subnet-a
description: my build subnet via yc
network_id: enplguu8t6nqraj8upp2
zone_id: ru-central1-a
v4_cidr_blocks:
- 10.1.2.0/24

[gnoy@manjarokde-ws01 packer]$ packer validate centos-7-base.json.pkr.hcl 
The configuration is valid.
[gnoy@manjarokde-ws01 packer]$ packer build centos-7-base.json.pkr.hcl 
yandex.autogenerated_1: output will be in this color.

==> yandex.autogenerated_1: Creating temporary RSA SSH key for instance...
==> yandex.autogenerated_1: Using as source image: fd82n2d2h9fet9648lej (name: "centos-7-v20220214", family: "centos-7")
==> yandex.autogenerated_1: Use provided subnet id e9b3hea97tekhsgsg754
==> yandex.autogenerated_1: Creating disk...
==> yandex.autogenerated_1: Creating instance...
==> yandex.autogenerated_1: Waiting for instance with id fhm9a30a18gh5f36vqcl to become active...
    yandex.autogenerated_1: Detected instance IP: 62.84.126.154
==> yandex.autogenerated_1: Using SSH communicator to connect: 62.84.126.154
==> yandex.autogenerated_1: Waiting for SSH to become available...
==> yandex.autogenerated_1: Connected to SSH!
==> yandex.autogenerated_1: Provisioning with shell script: /tmp/packer-shell1050057154
    yandex.autogenerated_1: Loaded plugins: fastestmirror
    yandex.autogenerated_1: Loading mirror speeds from cached hostfile
    yandex.autogenerated_1:  * base: mirror.reconn.ru
    yandex.autogenerated_1:  * extras: mirror.reconn.ru
    yandex.autogenerated_1:  * updates: centos-mirror.rbc.ru
    yandex.autogenerated_1: No packages marked for update
    yandex.autogenerated_1: Loaded plugins: fastestmirror
    yandex.autogenerated_1: Loading mirror speeds from cached hostfile
    yandex.autogenerated_1:  * base: mirror.reconn.ru
    yandex.autogenerated_1:  * extras: centos-mirror.rbc.ru
    yandex.autogenerated_1:  * updates: centos-mirror.rbc.ru
    yandex.autogenerated_1: Package iptables-1.4.21-35.el7.x86_64 already installed and latest version
    yandex.autogenerated_1: Package curl-7.29.0-59.el7_9.1.x86_64 already installed and latest version
    yandex.autogenerated_1: Package net-tools-2.0-0.25.20131004git.el7.x86_64 already installed and latest version
    yandex.autogenerated_1: Package rsync-3.1.2-10.el7.x86_64 already installed and latest version
    yandex.autogenerated_1: Package openssh-server-7.4p1-22.el7_9.x86_64 already installed and latest version
    yandex.autogenerated_1: Resolving Dependencies
    yandex.autogenerated_1: --> Running transaction check
    yandex.autogenerated_1: ---> Package bind-utils.x86_64 32:9.11.4-26.P2.el7_9.8 will be installed
    yandex.autogenerated_1: --> Processing Dependency: bind-libs-lite(x86-64) = 32:9.11.4-26.P2.el7_9.8 for package: 32:bind-utils-9.11.4-26.P2.el7_9.8.x86_64
    yandex.autogenerated_1: --> Processing Dependency: bind-libs(x86-64) = 32:9.11.4-26.P2.el7_9.8 for package: 32:bind-utils-9.11.4-26.P2.el7_9.8.x86_64
    yandex.autogenerated_1: --> Processing Dependency: liblwres.so.160()(64bit) for package: 32:bind-utils-9.11.4-26.P2.el7_9.8.x86_64
    yandex.autogenerated_1: --> Processing Dependency: libisccfg.so.160()(64bit) for package: 32:bind-utils-9.11.4-26.P2.el7_9.8.x86_64
    yandex.autogenerated_1: --> Processing Dependency: libisc.so.169()(64bit) for package: 32:bind-utils-9.11.4-26.P2.el7_9.8.x86_64
    yandex.autogenerated_1: --> Processing Dependency: libirs.so.160()(64bit) for package: 32:bind-utils-9.11.4-26.P2.el7_9.8.x86_64
    yandex.autogenerated_1: --> Processing Dependency: libdns.so.1102()(64bit) for package: 32:bind-utils-9.11.4-26.P2.el7_9.8.x86_64
    yandex.autogenerated_1: --> Processing Dependency: libbind9.so.160()(64bit) for package: 32:bind-utils-9.11.4-26.P2.el7_9.8.x86_64
    yandex.autogenerated_1: --> Processing Dependency: libGeoIP.so.1()(64bit) for package: 32:bind-utils-9.11.4-26.P2.el7_9.8.x86_64
    yandex.autogenerated_1: ---> Package bridge-utils.x86_64 0:1.5-9.el7 will be installed
    yandex.autogenerated_1: ---> Package tcpdump.x86_64 14:4.9.2-4.el7_7.1 will be installed
    yandex.autogenerated_1: --> Processing Dependency: libpcap >= 14:1.5.3-10 for package: 14:tcpdump-4.9.2-4.el7_7.1.x86_64
    yandex.autogenerated_1: --> Processing Dependency: libpcap.so.1()(64bit) for package: 14:tcpdump-4.9.2-4.el7_7.1.x86_64
    yandex.autogenerated_1: ---> Package telnet.x86_64 1:0.17-66.el7 will be installed
    yandex.autogenerated_1: --> Running transaction check
    yandex.autogenerated_1: ---> Package GeoIP.x86_64 0:1.5.0-14.el7 will be installed
    yandex.autogenerated_1: --> Processing Dependency: geoipupdate for package: GeoIP-1.5.0-14.el7.x86_64
    yandex.autogenerated_1: ---> Package bind-libs.x86_64 32:9.11.4-26.P2.el7_9.8 will be installed
    yandex.autogenerated_1: --> Processing Dependency: bind-license = 32:9.11.4-26.P2.el7_9.8 for package: 32:bind-libs-9.11.4-26.P2.el7_9.8.x86_64
    yandex.autogenerated_1: ---> Package bind-libs-lite.x86_64 32:9.11.4-26.P2.el7_9.8 will be installed
    yandex.autogenerated_1: ---> Package libpcap.x86_64 14:1.5.3-12.el7 will be installed
    yandex.autogenerated_1: --> Running transaction check
    yandex.autogenerated_1: ---> Package bind-license.noarch 32:9.11.4-26.P2.el7_9.8 will be installed
    yandex.autogenerated_1: ---> Package geoipupdate.x86_64 0:2.5.0-1.el7 will be installed
    yandex.autogenerated_1: --> Finished Dependency Resolution
    yandex.autogenerated_1:
    yandex.autogenerated_1: Dependencies Resolved
    yandex.autogenerated_1:
    yandex.autogenerated_1: ================================================================================
    yandex.autogenerated_1:  Package            Arch       Version                        Repository   Size
    yandex.autogenerated_1: ================================================================================
    yandex.autogenerated_1: Installing:
    yandex.autogenerated_1:  bind-utils         x86_64     32:9.11.4-26.P2.el7_9.8        updates     261 k
    yandex.autogenerated_1:  bridge-utils       x86_64     1.5-9.el7                      base         32 k
    yandex.autogenerated_1:  tcpdump            x86_64     14:4.9.2-4.el7_7.1             base        422 k
    yandex.autogenerated_1:  telnet             x86_64     1:0.17-66.el7                  updates      64 k
    yandex.autogenerated_1: Installing for dependencies:
    yandex.autogenerated_1:  GeoIP              x86_64     1.5.0-14.el7                   base        1.5 M
    yandex.autogenerated_1:  bind-libs          x86_64     32:9.11.4-26.P2.el7_9.8        updates     157 k
    yandex.autogenerated_1:  bind-libs-lite     x86_64     32:9.11.4-26.P2.el7_9.8        updates     1.1 M
    yandex.autogenerated_1:  bind-license       noarch     32:9.11.4-26.P2.el7_9.8        updates      91 k
    yandex.autogenerated_1:  geoipupdate        x86_64     2.5.0-1.el7                    base         35 k
    yandex.autogenerated_1:  libpcap            x86_64     14:1.5.3-12.el7                base        139 k
    yandex.autogenerated_1:
    yandex.autogenerated_1: Transaction Summary
    yandex.autogenerated_1: ================================================================================
    yandex.autogenerated_1: Install  4 Packages (+6 Dependent packages)
    yandex.autogenerated_1:
    yandex.autogenerated_1: Total download size: 3.8 M
    yandex.autogenerated_1: Installed size: 9.0 M
    yandex.autogenerated_1: Downloading packages:
    yandex.autogenerated_1: --------------------------------------------------------------------------------
    yandex.autogenerated_1: Total                                               13 MB/s | 3.8 MB  00:00
    yandex.autogenerated_1: Running transaction check
    yandex.autogenerated_1: Running transaction test
    yandex.autogenerated_1: Transaction test succeeded
    yandex.autogenerated_1: Running transaction
    yandex.autogenerated_1:   Installing : 32:bind-license-9.11.4-26.P2.el7_9.8.noarch                 1/10
    yandex.autogenerated_1:   Installing : geoipupdate-2.5.0-1.el7.x86_64                              2/10
    yandex.autogenerated_1:   Installing : GeoIP-1.5.0-14.el7.x86_64                                   3/10
    yandex.autogenerated_1:   Installing : 32:bind-libs-lite-9.11.4-26.P2.el7_9.8.x86_64               4/10
    yandex.autogenerated_1:   Installing : 32:bind-libs-9.11.4-26.P2.el7_9.8.x86_64                    5/10
    yandex.autogenerated_1:   Installing : 14:libpcap-1.5.3-12.el7.x86_64                              6/10
    yandex.autogenerated_1: pam_tally2: Error opening /var/log/tallylog for update: Permission denied
    yandex.autogenerated_1: pam_tally2: Authentication error
    yandex.autogenerated_1: useradd: failed to reset the tallylog entry of user "tcpdump"
    yandex.autogenerated_1:   Installing : 14:tcpdump-4.9.2-4.el7_7.1.x86_64                           7/10
    yandex.autogenerated_1:   Installing : 32:bind-utils-9.11.4-26.P2.el7_9.8.x86_64                   8/10
    yandex.autogenerated_1:   Installing : bridge-utils-1.5-9.el7.x86_64                               9/10
    yandex.autogenerated_1:   Installing : 1:telnet-0.17-66.el7.x86_64                                10/10
    yandex.autogenerated_1:   Verifying  : GeoIP-1.5.0-14.el7.x86_64                                   1/10
    yandex.autogenerated_1:   Verifying  : 1:telnet-0.17-66.el7.x86_64                                 2/10
    yandex.autogenerated_1:   Verifying  : 14:libpcap-1.5.3-12.el7.x86_64                              3/10
    yandex.autogenerated_1:   Verifying  : geoipupdate-2.5.0-1.el7.x86_64                              4/10
    yandex.autogenerated_1:   Verifying  : 14:tcpdump-4.9.2-4.el7_7.1.x86_64                           5/10
    yandex.autogenerated_1:   Verifying  : 32:bind-license-9.11.4-26.P2.el7_9.8.noarch                 6/10
    yandex.autogenerated_1:   Verifying  : 32:bind-libs-lite-9.11.4-26.P2.el7_9.8.x86_64               7/10
    yandex.autogenerated_1:   Verifying  : 32:bind-utils-9.11.4-26.P2.el7_9.8.x86_64                   8/10
    yandex.autogenerated_1:   Verifying  : 32:bind-libs-9.11.4-26.P2.el7_9.8.x86_64                    9/10
    yandex.autogenerated_1:   Verifying  : bridge-utils-1.5-9.el7.x86_64                              10/10
    yandex.autogenerated_1:
    yandex.autogenerated_1: Installed:
    yandex.autogenerated_1:   bind-utils.x86_64 32:9.11.4-26.P2.el7_9.8   bridge-utils.x86_64 0:1.5-9.el7
    yandex.autogenerated_1:   tcpdump.x86_64 14:4.9.2-4.el7_7.1           telnet.x86_64 1:0.17-66.el7
    yandex.autogenerated_1:
    yandex.autogenerated_1: Dependency Installed:
    yandex.autogenerated_1:   GeoIP.x86_64 0:1.5.0-14.el7
    yandex.autogenerated_1:   bind-libs.x86_64 32:9.11.4-26.P2.el7_9.8
    yandex.autogenerated_1:   bind-libs-lite.x86_64 32:9.11.4-26.P2.el7_9.8
    yandex.autogenerated_1:   bind-license.noarch 32:9.11.4-26.P2.el7_9.8
    yandex.autogenerated_1:   geoipupdate.x86_64 0:2.5.0-1.el7
    yandex.autogenerated_1:   libpcap.x86_64 14:1.5.3-12.el7
    yandex.autogenerated_1:
    yandex.autogenerated_1: Complete!
==> yandex.autogenerated_1: Stopping instance...
==> yandex.autogenerated_1: Deleting instance...
    yandex.autogenerated_1: Instance has been deleted!
==> yandex.autogenerated_1: Creating image: centos-7-base
==> yandex.autogenerated_1: Waiting for image to complete...
==> yandex.autogenerated_1: Success image create...
==> yandex.autogenerated_1: Destroying boot disk...
    yandex.autogenerated_1: Disk has been deleted!
Build 'yandex.autogenerated_1' finished after 2 minutes 7 seconds.

==> Wait completed after 2 minutes 7 seconds

==> Builds finished. The artifacts of successful builds are:
--> yandex.autogenerated_1: A disk image was created: centos-7-base (id: fd88bbgjvrb66jdheg9o) with family name centos
[gnoy@manjarokde-ws01 packer]$ yc vpc subnet delete --name my-subnet-a && yc vpc network delete --name net 
done (7s)
[gnoy@manjarokde-ws01 packer]$ yc iam service-account list
+----------------------+----------------+
|          ID          |      NAME      |
+----------------------+----------------+
| ajen1emrcbm11h42ui8i | netology-robot |
+----------------------+----------------+
[gnoy@manjarokde-ws01 packer]$ yc compute image list
+----------------------+---------------+--------+----------------------+--------+
|          ID          |     NAME      | FAMILY |     PRODUCT IDS      | STATUS |
+----------------------+---------------+--------+----------------------+--------+
| fd88bbgjvrb66jdheg9o | centos-7-base | centos | f2epin40q8nh7fqdv3sh | READY  |
+----------------------+---------------+--------+----------------------+--------+
[gnoy@manjarokde-ws01 packer]$ cd ../terraform/
[gnoy@manjarokde-ws01 terraform]$ yc iam key create --service-account-name netology-robot --output key.json
id: ajelc3hen9797ae1olpr
service_account_id: ajen1emrcbm11h42ui8i
created_at: "2022-02-15T11:24:09.654215869Z"
key_algorithm: RSA_2048
```
Запускаем deploy. Ждем...
```bash
[gnoy@manjarokde-ws01 terraform]$ terraform init -upgrade

Initializing the backend...

Initializing provider plugins...
- Finding latest version of yandex-cloud/yandex...
- Finding latest version of hashicorp/null...
- Finding latest version of hashicorp/local...
- Using previously-installed yandex-cloud/yandex v0.71.0
- Using previously-installed hashicorp/null v3.1.0
- Using previously-installed hashicorp/local v2.1.0

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
[gnoy@manjarokde-ws01 terraform]$ terraform apply -auto-approve

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # local_file.inventory will be created
  + resource "local_file" "inventory" {
      + content              = (known after apply)
      + directory_permission = "0777"
      + file_permission      = "0777"
      + filename             = "../ansible/inventory"
      + id                   = (known after apply)
    }

  # null_resource.docker will be created
  + resource "null_resource" "docker" {
      + id = (known after apply)
    }

  # null_resource.postgresql will be created
  + resource "null_resource" "postgresql" {
      + id = (known after apply)
    }

  # null_resource.start will be created
  + resource "null_resource" "start" {
      + id = (known after apply)
    }

  # null_resource.wait will be created
  + resource "null_resource" "wait" {
      + id = (known after apply)
    }

  # yandex_compute_instance.node01 will be created
  + resource "yandex_compute_instance" "node01" {
      + allow_stopping_for_update = true
      + created_at                = (known after apply)
      + folder_id                 = (known after apply)
      + fqdn                      = (known after apply)
      + hostname                  = "node01.netology.yc"
      + id                        = (known after apply)
      + metadata                  = {
          + "ssh-keys" = <<-EOT
                centos:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDAQrqhEDvkOhgrnOksf0Q/8iHIafkADpI+dabnPVGrjfEilNcIW+WH0wPDO53nDJqPgKFE9eZ+5CpMEkMX96SoR2fmdmx80qVKGW6/5z9IMtHnzpVkAVtSDguA/JV/bMP4vwov/DsvDN+/FwJ16EwX0t3Q5VgELYw/o6I1u981CCj+VdmjE7xdf8dNI+jvHN+ho59C1TXhUBevluAjB3MhRe+/chA524gYvf1L6APuCC05u+bV7YCKiQTugVE17oFDzTu76PQ/qRtvxZGk+p4+DWSluwNQL+6oM1zEjH6anqV7QEFpoKTPU5nAKh6mV3xSNUkiJfc6qnZHKLdAOm4qozEPvx6nYw9pypaVUwK35+L4hTPt/fAXjqcItsUK9v0vDdhwiYydgSItoxsDEvyevySwLTkJugtwuEwVShCSPcWN8fq5FwxEV/4fhJDrOimbE+hV11k3/5JfuHoN92z5ucJgF8QLIfPkBxSjRXXEqVfhqg6JTqTWBx6l4mxE2OWQ==
            EOT
        }
      + name                      = "node01"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v1"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-a"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + block_size  = (known after apply)
              + description = (known after apply)
              + image_id    = "fd88bbgjvrb66jdheg9o"
              + name        = "root-node01"
              + size        = 10
              + snapshot_id = (known after apply)
              + type        = "network-nvme"
            }
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = "192.168.101.11"
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = true
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + placement_policy {
          + placement_group_id = (known after apply)
        }

      + resources {
          + core_fraction = 5
          + cores         = 2
          + memory        = 2
        }

      + scheduling_policy {
          + preemptible = (known after apply)
        }
    }

  # yandex_vpc_network.default will be created
  + resource "yandex_vpc_network" "default" {
      + created_at                = (known after apply)
      + default_security_group_id = (known after apply)
      + folder_id                 = (known after apply)
      + id                        = (known after apply)
      + labels                    = (known after apply)
      + name                      = "net"
      + subnet_ids                = (known after apply)
    }

  # yandex_vpc_subnet.default will be created
  + resource "yandex_vpc_subnet" "default" {
      + created_at     = (known after apply)
      + folder_id      = (known after apply)
      + id             = (known after apply)
      + labels         = (known after apply)
      + name           = "subnet"
      + network_id     = (known after apply)
      + v4_cidr_blocks = [
          + "192.168.101.0/24",
        ]
      + v6_cidr_blocks = (known after apply)
      + zone           = "ru-central1-a"
    }

Plan: 8 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + external_ip_address_node01 = (known after apply)
  + internal_ip_address_node01 = "192.168.101.11"
yandex_vpc_network.default: Creating...
yandex_vpc_network.default: Creation complete after 1s [id=enpeidahnlascijjl404]
yandex_vpc_subnet.default: Creating...
yandex_vpc_subnet.default: Creation complete after 0s [id=e9bmlnkh19onrt8gjku5]
yandex_compute_instance.node01: Creating...
yandex_compute_instance.node01: Still creating... [10s elapsed]
yandex_compute_instance.node01: Still creating... [20s elapsed]
yandex_compute_instance.node01: Still creating... [30s elapsed]
yandex_compute_instance.node01: Still creating... [40s elapsed]
yandex_compute_instance.node01: Creation complete after 42s [id=fhmsa1lr534ml82nqns0]
local_file.inventory: Creating...
local_file.inventory: Creation complete after 0s [id=c92a8c6237cc9b37d827d734b79ccd50e0ab970c]
null_resource.wait: Creating...
null_resource.wait: Provisioning with 'local-exec'...
null_resource.wait (local-exec): Executing: ["/bin/sh" "-c" "sleep 100"]
null_resource.wait: Still creating... [10s elapsed]
null_resource.wait: Still creating... [20s elapsed]
null_resource.wait: Still creating... [30s elapsed]
null_resource.wait: Still creating... [40s elapsed]
null_resource.wait: Still creating... [50s elapsed]
null_resource.wait: Still creating... [1m0s elapsed]
null_resource.wait: Still creating... [1m10s elapsed]
null_resource.wait: Still creating... [1m20s elapsed]
null_resource.wait: Still creating... [1m30s elapsed]
null_resource.wait: Still creating... [1m40s elapsed]
null_resource.wait: Creation complete after 1m40s [id=2159366637556780777]
null_resource.docker: Creating...
null_resource.docker: Provisioning with 'local-exec'...
null_resource.docker (local-exec): Executing: ["/bin/sh" "-c" "ANSIBLE_FORCE_COLOR=1 ansible-playbook -i ../ansible/inventory ../ansible/docker-deploy.yml"]

null_resource.docker (local-exec): PLAY [Install of Requrements Tools] ********************************************

null_resource.docker (local-exec): TASK [Gathering Facts] *********************************************************
null_resource.docker (local-exec): ok: [node01.netology.yc]

null_resource.docker (local-exec): TASK [install-tools : Installing tools] ****************************************
null_resource.docker (local-exec): ok: [node01.netology.yc] => (item=python)

null_resource.docker (local-exec): TASK [configure-hosts-file : Configure Hosts File] *****************************
null_resource.docker (local-exec): changed: [node01.netology.yc] => (item=node01.netology.yc)

null_resource.docker (local-exec): PLAY [Install Docker Engine] ***************************************************

null_resource.docker (local-exec): TASK [Gathering Facts] *********************************************************
null_resource.docker: Still creating... [10s elapsed]
null_resource.docker (local-exec): ok: [node01.netology.yc]

null_resource.docker (local-exec): TASK [docker-installation : Add docker repository] *****************************
null_resource.docker (local-exec): changed: [node01.netology.yc]

null_resource.docker (local-exec): TASK [docker-installation : Installing docker package] *************************
null_resource.docker: Still creating... [20s elapsed]
null_resource.docker: Still creating... [30s elapsed]
null_resource.docker: Still creating... [40s elapsed]
null_resource.docker: Still creating... [50s elapsed]
null_resource.docker: Still creating... [1m0s elapsed]
null_resource.docker: Still creating... [1m10s elapsed]
null_resource.docker: Still creating... [1m20s elapsed]
null_resource.docker: Still creating... [1m30s elapsed]
null_resource.docker: Still creating... [1m40s elapsed]
null_resource.docker (local-exec): changed: [node01.netology.yc] => (item=docker-ce)
null_resource.docker (local-exec): ok: [node01.netology.yc] => (item=docker-ce-cli)
null_resource.docker (local-exec): ok: [node01.netology.yc] => (item=containerd.io)

null_resource.docker (local-exec): TASK [docker-installation : Enable docker daemon] ******************************
null_resource.docker: Still creating... [1m50s elapsed]
null_resource.docker (local-exec): changed: [node01.netology.yc]

null_resource.docker (local-exec): TASK [docker-installation : Install docker-compose from official github repo] ***
null_resource.docker (local-exec): changed: [node01.netology.yc]

null_resource.docker (local-exec): PLAY RECAP *********************************************************************
null_resource.docker (local-exec): node01.netology.yc         : ok=8    changed=5    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

null_resource.docker: Creation complete after 1m54s [id=5814736928899543857]
null_resource.postgresql: Creating...
null_resource.postgresql: Provisioning with 'local-exec'...
null_resource.postgresql (local-exec): Executing: ["/bin/sh" "-c" "ANSIBLE_FORCE_COLOR=1 ansible-playbook -i ../ansible/inventory ../ansible/sync-deploy.yml"]

null_resource.postgresql (local-exec): PLAY [nodes] *******************************************************************

null_resource.postgresql (local-exec): TASK [Gathering Facts] *********************************************************
null_resource.postgresql (local-exec): ok: [node01.netology.yc]

null_resource.postgresql (local-exec): TASK [Synchronization] *********************************************************
null_resource.postgresql (local-exec): changed: [node01.netology.yc]

null_resource.postgresql (local-exec): PLAY RECAP *********************************************************************
null_resource.postgresql (local-exec): node01.netology.yc         : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

null_resource.postgresql: Creation complete after 6s [id=4417829449239224817]
null_resource.start: Creating...
null_resource.start: Provisioning with 'local-exec'...
null_resource.start (local-exec): Executing: ["/bin/sh" "-c" "ANSIBLE_FORCE_COLOR=1 ansible-playbook -i ../ansible/inventory ../ansible/start-docker.yml"]

null_resource.start (local-exec): PLAY [nodes] *******************************************************************

null_resource.start (local-exec): TASK [Gathering Facts] *********************************************************
null_resource.start (local-exec): ok: [node01.netology.yc]

null_resource.start (local-exec): TASK [Run postgresql in docker] ************************************************
null_resource.start: Still creating... [10s elapsed]
null_resource.start: Still creating... [20s elapsed]
null_resource.start: Still creating... [30s elapsed]
null_resource.start: Still creating... [40s elapsed]
null_resource.start: Still creating... [50s elapsed]
null_resource.start (local-exec): changed: [node01.netology.yc]

null_resource.start (local-exec): PLAY RECAP *********************************************************************
null_resource.start (local-exec): node01.netology.yc         : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

null_resource.start: Creation complete after 58s [id=4748102748238921665]

Apply complete! Resources: 8 added, 0 changed, 0 destroyed.

Outputs:

external_ip_address_node01 = "84.201.130.143"
internal_ip_address_node01 = "192.168.101.11"

```
</details>

--  
docker-compose.yml
```bash
[gnoy@manjarokde-ws01 conf]$ cat docker-compose.yml 
version: '3.1'

services:
  pg_db:
    image: postgres:12
    restart: always
    container_name: postgres-12
    environment:
      - POSTGRES_PASSWORD=tmppassword
      - POSTGRES_USER=tmpuser
    volumes:
      - /opt/postgres/dbdata:/var/lib/postgresql/data
      - /opt/postgres/backup:/backup
    ports:
      - ${POSTGRES_PORT:-5432}:5432
```

## Задача 2

В БД из задачи 1: 
- создайте пользователя test-admin-user и БД test_db
- в БД test_db создайте таблицу orders и clients (спeцификация таблиц ниже)
- предоставьте привилегии на все операции пользователю test-admin-user на таблицы БД test_db
- создайте пользователя test-simple-user  
- предоставьте пользователю test-simple-user права на SELECT/INSERT/UPDATE/DELETE данных таблиц БД test_db

Таблица orders:
- id (serial primary key)
- наименование (string)
- цена (integer)

Таблица clients:
- id (serial primary key)
- фамилия (string)
- страна проживания (string, index)
- заказ (foreign key orders)

Приведите:
- итоговый список БД после выполнения пунктов выше,
- описание таблиц (describe)
- SQL-запрос для выдачи списка пользователей с правами над таблицами test_db
- список пользователей с правами над таблицами test_db  

Ответ:  
Под спойлером спрятаны промежуточные шаги, не относящиеся к конкретному решению представленной задачи в ДЗ.

<details>
  <summary>Console</summary>

Подключаемся к ВМ в облаке, к контейнеру. Далее работаем непосредственно в нем.
```bash
[gnoy@manjarokde-ws01 terraform]$ ssh centos@84.201.130.143
[centos@node01 ~]$ sudo docker ps
CONTAINER ID   IMAGE         COMMAND                  CREATED         STATUS         PORTS                                       NAMES
1045005f8e71   postgres:12   "docker-entrypoint.s…"   7 minutes ago   Up 7 minutes   0.0.0.0:5432->5432/tcp, :::5432->5432/tcp   postgres-12
[centos@node01 ~]$ sudo docker exec -it postgres-12 bash
root@1045005f8e71:/# 
```
Подключаемся к БД
```bash
root@1045005f8e71:/# psql -U tmpuser
psql (12.10 (Debian 12.10-1.pgdg110+1))
Type "help" for help.

tmpuser=#
```
</details>

--
- создайте пользователя test-admin-user и БД test_db
```bash
tmpuser=# CREATE DATABASE test_db;
CREATE DATABASE
test_db=# CREATE USER "test-admin-user" PASSWORD 'newpassword';
CREATE ROLE
```
- в БД test_db создайте таблицу orders и clients (спeцификация таблиц ниже)
```bash
test_db=# CREATE TABLE orders (id SERIAL NOT NULL primary key, наименование VARCHAR NOT NULL, цена INTEGER NOT NULL);
CREATE TABLE
test_db=# CREATE TABLE clients (id SERIAL NOT NULL primary key, фамилия VARCHAR NOT NULL, "страна проживания" VARCHAR NOT NULL, Заказ SERIAL NOT NULL REFERENCES orders (id));
CREATE TABLE
test_db=# CREATE INDEX "страна проживания" ON clients ("страна проживания");
CREATE INDEX
```
- предоставьте привилегии на все операции пользователю test-admin-user на таблицы БД test_db
```bash
test_db=# GRANT ALL ON ALL TABLES IN SCHEMA public TO "test-admin-user";
GRANT
```
- создайте пользователя test-simple-user  
```bash
test_db=# CREATE USER "test-simple-user" WITH PASSWORD 'passwordnew';
CREATE ROLE
```
- предоставьте пользователю test-simple-user права на SELECT/INSERT/UPDATE/DELETE данных таблиц БД test_db
```bash
test_db=# GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO "test-simple-user";
GRANT
```

Привожу:
- итоговый список БД после выполнения пунктов выше
```bash
test_db=# \l
                               List of databases
   Name    |  Owner  | Encoding |  Collate   |   Ctype    |  Access privileges  
-----------+---------+----------+------------+------------+---------------------
 postgres  | tmpuser | UTF8     | en_US.utf8 | en_US.utf8 | 
 template0 | tmpuser | UTF8     | en_US.utf8 | en_US.utf8 | =c/tmpuser         +
           |         |          |            |            | tmpuser=CTc/tmpuser
 template1 | tmpuser | UTF8     | en_US.utf8 | en_US.utf8 | =c/tmpuser         +
           |         |          |            |            | tmpuser=CTc/tmpuser
 test_db   | tmpuser | UTF8     | en_US.utf8 | en_US.utf8 | 
 tmpuser   | tmpuser | UTF8     | en_US.utf8 | en_US.utf8 | 
(5 rows)
```
- описание таблиц (describe)
```bash
test_db=# \d public.orders
                                    Table "public.orders"
    Column    |       Type        | Collation | Nullable |              Default               
--------------+-------------------+-----------+----------+------------------------------------
 id           | integer           |           | not null | nextval('orders_id_seq'::regclass)
 наименование | character varying |           | not null | 
 цена         | integer           |           | not null | 
Indexes:
    "orders_pkey" PRIMARY KEY, btree (id)
Referenced by:
    TABLE "clients" CONSTRAINT "clients_заказ_fkey" FOREIGN KEY ("заказ") REFERENCES orders(id)

test_db=# \d public.clients
                                         Table "public.clients"
      Column       |       Type        | Collation | Nullable |                 Default                  
-------------------+-------------------+-----------+----------+------------------------------------------
 id                | integer           |           | not null | nextval('clients_id_seq'::regclass)
 фамилия           | character varying |           | not null | 
 страна проживания | character varying |           | not null | 
 заказ             | integer           |           | not null | nextval('"clients_заказ_seq"'::regclass)
Indexes:
    "clients_pkey" PRIMARY KEY, btree (id)
    "страна проживания" btree ("страна проживания")
Foreign-key constraints:
    "clients_заказ_fkey" FOREIGN KEY ("заказ") REFERENCES orders(id)
```
- SQL-запрос для выдачи списка пользователей с правами над таблицами test_db
```bash
test_db=# SELECT * FROM information_schema.table_privileges WHERE grantee IN ('test-admin-user', 'test-simple-user');
 grantor |     grantee      | table_catalog | table_schema | table_name | privilege_type | is_grantable | with_hierarchy 
---------+------------------+---------------+--------------+------------+----------------+--------------+----------------
 tmpuser | test-admin-user  | test_db       | public       | orders     | INSERT         | NO           | NO
 tmpuser | test-admin-user  | test_db       | public       | orders     | SELECT         | NO           | YES
 tmpuser | test-admin-user  | test_db       | public       | orders     | UPDATE         | NO           | NO
 tmpuser | test-admin-user  | test_db       | public       | orders     | DELETE         | NO           | NO
 tmpuser | test-admin-user  | test_db       | public       | orders     | TRUNCATE       | NO           | NO
 tmpuser | test-admin-user  | test_db       | public       | orders     | REFERENCES     | NO           | NO
 tmpuser | test-admin-user  | test_db       | public       | orders     | TRIGGER        | NO           | NO
 tmpuser | test-simple-user | test_db       | public       | orders     | INSERT         | NO           | NO
 tmpuser | test-simple-user | test_db       | public       | orders     | SELECT         | NO           | YES
 tmpuser | test-simple-user | test_db       | public       | orders     | UPDATE         | NO           | NO
 tmpuser | test-simple-user | test_db       | public       | orders     | DELETE         | NO           | NO
 tmpuser | test-admin-user  | test_db       | public       | clients    | INSERT         | NO           | NO
 tmpuser | test-admin-user  | test_db       | public       | clients    | SELECT         | NO           | YES
 tmpuser | test-admin-user  | test_db       | public       | clients    | UPDATE         | NO           | NO
 tmpuser | test-admin-user  | test_db       | public       | clients    | DELETE         | NO           | NO
 tmpuser | test-admin-user  | test_db       | public       | clients    | TRUNCATE       | NO           | NO
 tmpuser | test-admin-user  | test_db       | public       | clients    | REFERENCES     | NO           | NO
 tmpuser | test-admin-user  | test_db       | public       | clients    | TRIGGER        | NO           | NO
 tmpuser | test-simple-user | test_db       | public       | clients    | INSERT         | NO           | NO
 tmpuser | test-simple-user | test_db       | public       | clients    | SELECT         | NO           | YES
 tmpuser | test-simple-user | test_db       | public       | clients    | UPDATE         | NO           | NO
 tmpuser | test-simple-user | test_db       | public       | clients    | DELETE         | NO           | NO
(22 rows)
```
- список пользователей с правами над таблицами test_db  
```bash
test_db=# \dp
                                            Access privileges
 Schema |       Name        |   Type   |         Access privileges         | Column privileges | Policies 
--------+-------------------+----------+-----------------------------------+-------------------+----------
 public | clients           | table    | tmpuser=arwdDxt/tmpuser          +|                   | 
        |                   |          | "test-admin-user"=arwdDxt/tmpuser+|                   | 
        |                   |          | "test-simple-user"=arwd/tmpuser   |                   | 
 public | clients_id_seq    | sequence |                                   |                   | 
 public | clients_заказ_seq | sequence |                                   |                   | 
 public | orders            | table    | tmpuser=arwdDxt/tmpuser          +|                   | 
        |                   |          | "test-admin-user"=arwdDxt/tmpuser+|                   | 
        |                   |          | "test-simple-user"=arwd/tmpuser   |                   | 
 public | orders_id_seq     | sequence |                                   |                   | 
(5 rows)
```

## Задача 3

Используя SQL синтаксис - наполните таблицы следующими тестовыми данными:

Таблица orders

|Наименование|цена|
|------------|----|
|Шоколад| 10 |
|Принтер| 3000 |
|Книга| 500 |
|Монитор| 7000|
|Гитара| 4000|

Таблица clients

|ФИО|Страна проживания|
|------------|----|
|Иванов Иван Иванович| USA |
|Петров Петр Петрович| Canada |
|Иоганн Себастьян Бах| Japan |
|Ронни Джеймс Дио| Russia|
|Ritchie Blackmore| Russia|

Используя SQL синтаксис:
- вычислите количество записей для каждой таблицы 
- приведите в ответе:
    - запросы 
    - результаты их выполнения.

Ответ:  
- Используя SQL синтаксис - наполните таблицы следующими тестовыми данными  

orders:
```bash
test_db=# INSERT INTO orders (наименование, цена) VALUES ('Шоколад', 10);
INSERT 0 1
test_db=# INSERT INTO orders (наименование, цена) VALUES ('Принтер', 3000);
INSERT 0 1
test_db=# INSERT INTO orders (наименование, цена) VALUES ('Книга', 500);
INSERT 0 1
test_db=# INSERT INTO orders (наименование, цена) VALUES ('Монитор', 7000);
INSERT 0 1
test_db=# INSERT INTO orders (наименование, цена) VALUES ('Гитара', 4000);
INSERT 0 1
test_db=# SELECT * FROM orders;
 id | наименование | цена 
----+--------------+------
  1 | Шоколад      |   10
  2 | Принтер      | 3000
  3 | Книга        |  500
  4 | Монитор      | 7000
  5 | Гитара       | 4000
(5 rows)
```
clients:
```bash
test_db=# INSERT INTO clients (фамилия, "страна проживания") VALUES ('Иванов Иван Иванович', 'USA');
INSERT 0 1
test_db=# INSERT INTO clients (фамилия, "страна проживания") VALUES ('Петров Петр Петрович', 'Canada');
INSERT 0 1
test_db=# INSERT INTO clients (фамилия, "страна проживания") VALUES ('Иоганн Себастьян Бах', 'Japan');
INSERT 0 1
test_db=# INSERT INTO clients (фамилия, "страна проживания") VALUES ('Ронни Джеймс Дио', 'Russia');
INSERT 0 1
test_db=# INSERT INTO clients (фамилия, "страна проживания") VALUES ('Ritchie Blackmore', 'Russia');
INSERT 0 1
test_db=# SELECT * FROM clients;
 id |       фамилия        | страна проживания | заказ 
----+----------------------+-------------------+-------
  1 | Иванов Иван Иванович | USA               |     1
  2 | Петров Петр Петрович | Canada            |     2
  3 | Иоганн Себастьян Бах | Japan             |     3
  4 | Ронни Джеймс Дио     | Russia            |     4
  5 | Ritchie Blackmore    | Russia            |     5
(5 rows)
```
Используя SQL синтаксис:
- вычислите количество записей для каждой таблицы 
- приведите в ответе:
    - запросы 
    - результаты их выполнения.
```bash
test_db=# SELECT COUNT (*) FROM orders;
 count 
-------
     5
(1 row)

test_db=# SELECT COUNT (*) FROM clients;
 count 
-------
     5
(1 row)
```

## Задача 4

Часть пользователей из таблицы clients решили оформить заказы из таблицы orders.

Используя foreign keys свяжите записи из таблиц, согласно таблице:

|ФИО|Заказ|
|------------|----|
|Иванов Иван Иванович| Книга |
|Петров Петр Петрович| Монитор |
|Иоганн Себастьян Бах| Гитара |

Приведите SQL-запросы для выполнения данных операций.

Приведите SQL-запрос для выдачи всех пользователей, которые совершили заказ, а также вывод данного запроса.
 
Подсказк - используйте директиву `UPDATE`.  

Ответ:  
```bash
test_db=# UPDATE clients SET заказ=3 WHERE id=1;
UPDATE 1
test_db=# UPDATE clients SET заказ=4 WHERE id=2;
UPDATE 1
test_db=# UPDATE clients SET заказ=5 WHERE id=3;
UPDATE 1
test_db=# SELECT фамилия, заказ FROM clients WHERE id <> заказ;
       фамилия        | заказ 
----------------------+-------
 Иванов Иван Иванович |     3
 Петров Петр Петрович |     4
 Иоганн Себастьян Бах |     5
(3 rows)
```

## Задача 5

Получите полную информацию по выполнению запроса выдачи всех пользователей из задачи 4 
(используя директиву EXPLAIN).

Приведите получившийся результат и объясните что значат полученные значения.  

Ответ:  
```bash
test_db=# EXPLAIN SELECT фамилия, заказ FROM clients WHERE id <> заказ;
                        QUERY PLAN                         
-----------------------------------------------------------
 Seq Scan on clients  (cost=0.00..20.12 rows=806 width=36)
   Filter: (id <> "заказ")
(2 rows)
```
**cost** - имеет два значения. Первое (0.00) показывает приблизительное затраченное время на получение первого значения (первой строки). Второе значение (20.12) показывает приблизительное время затраченное на выполнение всего sql-запроса.  
**rows** - отображает число данных, обработанных для получения выходных данных.  
**width** - ожидаемый размер строк в байтах.

## Задача 6

Создайте бэкап БД test_db и поместите его в volume, предназначенный для бэкапов (см. Задачу 1).

Остановите контейнер с PostgreSQL (но не удаляйте volumes).

Поднимите новый пустой контейнер с PostgreSQL.

Восстановите БД test_db в новом контейнере.

Приведите список операций, который вы применяли для бэкапа данных и восстановления.   

Ответ:  
Создаем бекап, находясь в контейнере:
```bash
root@6af8a076b720:/# pg_dumpall -U tmpuser > /backup/test_db_backup.dump
root@6af8a076b720:/# ls -lh /backup/
total 12K
-rw-r--r--. 1 root root 9.0K Feb 19 06:10 test_db_backup.dump
```
Выходим из контейнера, проверяем наличие бекапа на хостовой ВМ, останавливаем контейнер:
```bash
[centos@node01 ~]$ sudo ls -lh /opt/postgres/backup/
total 12K
-rw-r--r--. 1 root root 9.0K Feb 19 06:10 test_db_backup.dump
[centos@node01 ~]$ sudo docker ps
CONTAINER ID   IMAGE         COMMAND                  CREATED             STATUS         PORTS                                       NAMES
6af8a076b720   postgres:12   "docker-entrypoint.s…"   About an hour ago   Up 2 minutes   0.0.0.0:5432->5432/tcp, :::5432->5432/tcp   postgres-12
[centos@node01 ~]$ sudo docker stop postgres-12
postgres-12
```
Поднимаем новый контейнер из командной строки на хостовой машине:
```bash
[centos@node01 ~]$ sudo docker run --name postgres-12-backup -e POSTGRES_PASSWORD=newpassword -v /opt/postgres/backup/:/backup/ -d -p 5432:5432 postgres:12
46a93aa346e5abbb3d38815d22887dc754308d13b41a3634a0cee02fceea2036
[centos@node01 ~]$ sudo docker ps
CONTAINER ID   IMAGE         COMMAND                  CREATED          STATUS          PORTS                                       NAMES
46a93aa346e5   postgres:12   "docker-entrypoint.s…"   11 seconds ago   Up 10 seconds   0.0.0.0:5432->5432/tcp, :::5432->5432/tcp   postgres-12-backup
```
Заходим в новый контейнер, восстанавливаем базу из бекапа:
```bash
[centos@node01 ~]$ sudo docker exec -it postgres-12-backup bash
root@46a93aa346e5:/# ls -lh /backup/
total 12K
-rw-r--r--. 1 root root 9.0K Feb 19 06:10 test_db_backup.dump
root@46a93aa346e5:/# psql -U postgres < /backup/test_db_backup.dump 
SET
SET
SET
CREATE ROLE
ALTER ROLE
CREATE ROLE
ALTER ROLE
CREATE ROLE
ALTER ROLE
You are now connected to database "template1" as user "postgres".
SET
SET
SET
SET
SET
 set_config 
------------
 
(1 row)

SET
SET
SET
SET
You are now connected to database "postgres" as user "postgres".
SET
SET
SET
SET
SET
 set_config 
------------
 
(1 row)

SET
SET
SET
SET
SET
SET
SET
SET
SET
 set_config 
------------
 
(1 row)

SET
SET
SET
SET
CREATE DATABASE
ALTER DATABASE
You are now connected to database "test_db" as user "postgres".
SET
SET
SET
SET
SET
 set_config 
------------
 
(1 row)

SET
SET
SET
SET
SET
SET
CREATE TABLE
ALTER TABLE
CREATE SEQUENCE
ALTER TABLE
ALTER SEQUENCE
CREATE SEQUENCE
ALTER TABLE
ALTER SEQUENCE
CREATE TABLE
ALTER TABLE
CREATE SEQUENCE
ALTER TABLE
ALTER SEQUENCE
ALTER TABLE
ALTER TABLE
ALTER TABLE
COPY 5
COPY 5
 setval 
--------
      5
(1 row)

 setval 
--------
      5
(1 row)

 setval 
--------
      5
(1 row)

ALTER TABLE
ALTER TABLE
CREATE INDEX
ALTER TABLE
GRANT
GRANT
GRANT
GRANT
SET
SET
SET
SET
SET
 set_config 
------------
 
(1 row)

SET
SET
SET
SET
CREATE DATABASE
ALTER DATABASE
You are now connected to database "tmpuser" as user "postgres".
SET
SET
SET
SET
SET
 set_config 
------------
 
(1 row)

SET
SET
SET
SET
```
Заходим в БД, проверяем наличие таблиц:
```bash
root@46a93aa346e5:/# psql test_db -U tmpuser
psql (12.10 (Debian 12.10-1.pgdg110+1))
Type "help" for help.

test_db=# \l
                                 List of databases
   Name    |  Owner   | Encoding |  Collate   |   Ctype    |   Access privileges   
-----------+----------+----------+------------+------------+-----------------------
 postgres  | postgres | UTF8     | en_US.utf8 | en_US.utf8 | 
 template0 | postgres | UTF8     | en_US.utf8 | en_US.utf8 | =c/postgres          +
           |          |          |            |            | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.utf8 | en_US.utf8 | =c/postgres          +
           |          |          |            |            | postgres=CTc/postgres
 test_db   | tmpuser  | UTF8     | en_US.utf8 | en_US.utf8 | 
 tmpuser   | tmpuser  | UTF8     | en_US.utf8 | en_US.utf8 | 
(5 rows)

test_db=# \dp
                                            Access privileges
 Schema |       Name        |   Type   |         Access privileges         | Column privileges | Policies 
--------+-------------------+----------+-----------------------------------+-------------------+----------
 public | clients           | table    | tmpuser=arwdDxt/tmpuser          +|                   | 
        |                   |          | "test-admin-user"=arwdDxt/tmpuser+|                   | 
        |                   |          | "test-simple-user"=arwd/tmpuser   |                   | 
 public | clients_id_seq    | sequence |                                   |                   | 
 public | clients_заказ_seq | sequence |                                   |                   | 
 public | orders            | table    | tmpuser=arwdDxt/tmpuser          +|                   | 
        |                   |          | "test-admin-user"=arwdDxt/tmpuser+|                   | 
        |                   |          | "test-simple-user"=arwd/tmpuser   |                   | 
 public | orders_id_seq     | sequence |                                   |                   | 
(5 rows)
```

Закончили с ДЗ. Сворачиваем облако

<details>
  <summary>Console</summary>

```bash
test_db-# \q
root@46a93aa346e5:/# exit
exit
[centos@node01 ~]$ exit
logout
Connection to 62.84.126.209 closed.
[gnoy@manjarokde-ws01 terraform]$ terraform destroy -auto-approve
yandex_vpc_network.default: Refreshing state... [id=enpfuetvhi7bbvjlfen6]
yandex_vpc_subnet.default: Refreshing state... [id=e9bdej2b87d10rsm9apj]
yandex_compute_instance.node01: Refreshing state... [id=fhmcjp1p56kmfrqe68t8]
local_file.inventory: Refreshing state... [id=68385fdf04009053353d58d7c7e576f3356a870c]
null_resource.wait: Refreshing state... [id=8657108184670928849]
null_resource.docker: Refreshing state... [id=7943593567254347886]
null_resource.postgresql: Refreshing state... [id=8356302983346083662]
null_resource.start: Refreshing state... [id=6071710721080822555]

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  # local_file.inventory will be destroyed
  - resource "local_file" "inventory" {
      - content              = <<-EOT
            # Ansible inventory containing variable values from Terraform.
            # Generated by Terraform.
            
            [nodes:children]
            node01
            
            [node01]
            node01.netology.yc ansible_host=62.84.126.209
        EOT -> null
      - directory_permission = "0777" -> null
      - file_permission      = "0777" -> null
      - filename             = "../ansible/inventory" -> null
      - id                   = "68385fdf04009053353d58d7c7e576f3356a870c" -> null
    }

  # null_resource.docker will be destroyed
  - resource "null_resource" "docker" {
      - id = "7943593567254347886" -> null
    }

  # null_resource.postgresql will be destroyed
  - resource "null_resource" "postgresql" {
      - id = "8356302983346083662" -> null
    }

  # null_resource.start will be destroyed
  - resource "null_resource" "start" {
      - id = "6071710721080822555" -> null
    }

  # null_resource.wait will be destroyed
  - resource "null_resource" "wait" {
      - id = "8657108184670928849" -> null
    }

  # yandex_compute_instance.node01 will be destroyed
  - resource "yandex_compute_instance" "node01" {
      - allow_stopping_for_update = true -> null
      - created_at                = "2022-02-19T04:46:42Z" -> null
      - folder_id                 = "b1g27gpcstr1l1bi3a22" -> null
      - fqdn                      = "node01.netology.yc" -> null
      - hostname                  = "node01" -> null
      - id                        = "fhmcjp1p56kmfrqe68t8" -> null
      - labels                    = {} -> null
      - metadata                  = {
          - "ssh-keys" = <<-EOT
                centos:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDAQrqhEDvkOhgrnOksf0Q/8iHIafkADpI+dabnPVGrjfEilNcIW+WH0wPDO53nDJqPgKFE9eZ+5CpMEkMX96SoR2fmdmx80qVKGW6/5z9IMtHnzpVkAVtSDguA/JV/bMP4vwov/DsvDN+/FwJ16EwX0t3Q5VgELYw/o6I1u981CCj+VdmjE7xdf8dNI+jvHN+ho59C1TXhUBevluAjB3MhRe+j3pN6slzXgS2Dun99GvNjPVD14V6piA2V7Cb88haJ7SfzvOV7CrZfsjFZ0Q4eEKy9F3aNUiL7q0DqrFpoXCfpqM1I9D7Kt1b02UjOemAmYrmLCo/chA524gYvf1L6APuCC05u+bV7YCKiQTugVE17oFDzTu76PQ/qRtvxZGk+p4+DWSluwNQL+6oM1zEjH6anqV7QEFpoKTPU5nAKh6mV3xSNUkiJfc6qnZHKLdAOm4qozEPvx6nYw9pypaVUwK35+L4hTPt/yILerk5FT1fFuMQnOK9S4aOyisLHN2a3FHDenWOUsQszLSzrJxNNvhDqTo/fAXjqcItsUK9v0vDdhwiYydgSItoxsDEvyevySwLTkJugtwuEwVShCSPcWN8fq5FwxEV/4fhJDrOimbE+hV11k3/5JfuHoN92z5ucJgF8QLIfPkBxSjRXXEqVfhqg6JTqTWBx6l4mxE2OWQ==
            EOT
        } -> null
      - name                      = "node01" -> null
      - network_acceleration_type = "standard" -> null
      - platform_id               = "standard-v1" -> null
      - status                    = "running" -> null
      - zone                      = "ru-central1-a" -> null

      - boot_disk {
          - auto_delete = true -> null
          - device_name = "fhmaac6q968r9iuf9bau" -> null
          - disk_id     = "fhmaac6q968r9iuf9bau" -> null
          - mode        = "READ_WRITE" -> null

          - initialize_params {
              - block_size = 4096 -> null
              - image_id   = "fd88bbgjvrb66jdheg9o" -> null
              - name       = "root-node01" -> null
              - size       = 10 -> null
              - type       = "network-hdd" -> null
            }
        }

      - network_interface {
          - index              = 0 -> null
          - ip_address         = "192.168.101.11" -> null
          - ipv4               = true -> null
          - ipv6               = false -> null
          - mac_address        = "d0:0d:c9:e4:39:29" -> null
          - nat                = true -> null
          - nat_ip_address     = "62.84.126.209" -> null
          - nat_ip_version     = "IPV4" -> null
          - security_group_ids = [] -> null
          - subnet_id          = "e9bdej2b87d10rsm9apj" -> null
        }

      - placement_policy {}

      - resources {
          - core_fraction = 5 -> null
          - cores         = 2 -> null
          - gpus          = 0 -> null
          - memory        = 2 -> null
        }

      - scheduling_policy {
          - preemptible = false -> null
        }
    }

  # yandex_vpc_network.default will be destroyed
  - resource "yandex_vpc_network" "default" {
      - created_at = "2022-02-19T04:46:39Z" -> null
      - folder_id  = "b1g27gpcstr1l1bi3a22" -> null
      - id         = "enpfuetvhi7bbvjlfen6" -> null
      - labels     = {} -> null
      - name       = "net" -> null
      - subnet_ids = [
          - "e9bdej2b87d10rsm9apj",
        ] -> null
    }

  # yandex_vpc_subnet.default will be destroyed
  - resource "yandex_vpc_subnet" "default" {
      - created_at     = "2022-02-19T04:46:40Z" -> null
      - folder_id      = "b1g27gpcstr1l1bi3a22" -> null
      - id             = "e9bdej2b87d10rsm9apj" -> null
      - labels         = {} -> null
      - name           = "subnet" -> null
      - network_id     = "enpfuetvhi7bbvjlfen6" -> null
      - v4_cidr_blocks = [
          - "192.168.101.0/24",
        ] -> null
      - v6_cidr_blocks = [] -> null
      - zone           = "ru-central1-a" -> null
    }

Plan: 0 to add, 0 to change, 8 to destroy.

Changes to Outputs:
  - external_ip_address_node01 = "62.84.126.209" -> null
  - internal_ip_address_node01 = "192.168.101.11" -> null
null_resource.start: Destroying... [id=6071710721080822555]
null_resource.start: Destruction complete after 0s
null_resource.postgresql: Destroying... [id=8356302983346083662]
null_resource.postgresql: Destruction complete after 0s
null_resource.docker: Destroying... [id=7943593567254347886]
null_resource.docker: Destruction complete after 0s
null_resource.wait: Destroying... [id=8657108184670928849]
null_resource.wait: Destruction complete after 0s
local_file.inventory: Destroying... [id=68385fdf04009053353d58d7c7e576f3356a870c]
local_file.inventory: Destruction complete after 0s
yandex_compute_instance.node01: Destroying... [id=fhmcjp1p56kmfrqe68t8]
yandex_compute_instance.node01: Still destroying... [id=fhmcjp1p56kmfrqe68t8, 10s elapsed]
yandex_compute_instance.node01: Destruction complete after 13s
yandex_vpc_subnet.default: Destroying... [id=e9bdej2b87d10rsm9apj]
yandex_vpc_subnet.default: Destruction complete after 2s
yandex_vpc_network.default: Destroying... [id=enpfuetvhi7bbvjlfen6]
yandex_vpc_network.default: Destruction complete after 1s

Destroy complete! Resources: 8 destroyed.
```

</details>